{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhWpGs6hF2Wl",
        "outputId": "39be2a47-a6f2-4e3c-dd9e-22d25ddbf290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (0.7)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.43.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Python version: 3.7.12\n",
            "Tensorflow version: 2.8.0\n",
            "Keras version: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "#Download and import necessary libraries\n",
        "!pip3 install pydicom matplotlib keras tensorflow pandas scikit-learn scipy glob2 \n",
        "import os\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import platform\n",
        "import datetime\n",
        "import math\n",
        "import random\n",
        "import pathlib\n",
        "import pydicom\n",
        "import cv2\n",
        "import glob\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "%tensorflow_version 2.x\n",
        "print('Python version:', platform.python_version())\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "print('Keras version:', tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNh7NID1F2Wv"
      },
      "outputs": [],
      "source": [
        "#Load Image dataset and Labels\n",
        "csv_file_dir = '/content/gdrive/My Drive/the real deal/labels.csv'\n",
        "img_file_dir = '/content/gdrive/My Drive/the real deal/head_ct'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-axWteUJtUSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69990125-1523-4e85-947d-3913f027778f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "# Load the TensorBoard notebook extension.\n",
        "# %reload_ext tensorboard\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EkieNmKtWoU"
      },
      "outputs": [],
      "source": [
        "# Clear any logs from previous runs.\n",
        "!rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLFk-9Z8F2Ww"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Loading and resizing 2D images.\n",
        "Parameters:\n",
        "    pathX: path to the images folder\n",
        "    pathY: path to the labels csv file\n",
        "\"\"\"\n",
        "#Use OpenCV to resize image to a smaller size then push the picture to a one dimension array with the pixels of the picture\n",
        "\n",
        "def load_samples_as_images(pathX, pathY,img_width, img_height):\n",
        "    files = sorted(glob.glob(pathX))\n",
        "    labels_df = pd.read_csv(pathY)\n",
        "    Y = np.array(labels_df[' hemorrhage'].tolist())\n",
        "    images = np.empty((len(files), img_width, img_height))\n",
        "\n",
        "    for i, _file in enumerate(files):\n",
        "        images[i, :, :] = cv2.resize(cv2.imread(_file, 0), (img_width, img_height))\n",
        "\n",
        "    return images, Y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6_9k57E-AdR",
        "outputId": "0aa8584c-4ec7-46a9-90e8-a449c2f14e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HemorrhageClassifier\n"
          ]
        }
      ],
      "source": [
        "def draw(images, labels):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(images[i], cmap=plt.get_cmap('gray'))\n",
        "        if labels[i] == 1:\n",
        "            plt.title(\"\\nLabel:{}\".format(\"Hemorrhage\"))\n",
        "        else:\n",
        "            plt.title(\"\\nLabel:{}\".format(\"No Hemorrhage\"))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def drawPredict(model, testX, testY, images, index):\n",
        "    modelName = str(model)\n",
        "    modelName = modelName.split(\"(\")[0]\n",
        "    rand = random.randint(0, 39)\n",
        "    inde = int(index[rand])\n",
        "    plt.imshow(images[inde])\n",
        "    if testY[rand] == 1:\n",
        "        plt.title(\"\\nLabel:{}\".format(\"Hemorrhage\"))\n",
        "    else:\n",
        "        plt.title(\"\\nLabel:{}\".format(\"No Hemorrhage\"))\n",
        "    plt.show()\n",
        "    predict = \"Hemorrhage\" if model.predict([testX[rand]]) == 1 else \"No Hemorrhage\"\n",
        "    label = \"Hemorrhage\" if testY[rand] == 1 else \"No Hemorrhage\"\n",
        "    print(\"The model\", modelName, \" predict:\", predict, \"the correct label:\", label)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = \"HemorrhageClassifier(n_jobs=-1, n_neighbors=2)\"\n",
        "    modelName = model.split(\"(\")[0]\n",
        "    print(modelName)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQoq1fnfF2W1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This class includes the methods to extract features from image.\n",
        "The features data must be a vector-shaped for the models we used, and\n",
        "yet preserve the important properties in the image.\n",
        "The methods converts 2D image to 1D vector:\n",
        "    image_to_vector - convert by resizing and then flatten the image.\n",
        "    image_to_histogram_vector - convert to image histogram.\n",
        "    fd_hu_moments - convert to 7-dimension vector describing the shapes in the image.\n",
        "    pca_reduction - usnig Principal Component Analysis for dimensionality reduction.\n",
        "    cany_edge - convert by finding the image edges and then flatten the image.\n",
        "\"\"\"\n",
        "from enum import Enum\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\"\"\"\n",
        "enum class: Represent the method to extract features from the input images \n",
        "\"\"\"\n",
        "class Method(Enum):\n",
        "    SIMPLE = 1\n",
        "    HISTOGRAM = 2\n",
        "    HUMOMENTS = 3\n",
        "    PCA = 4\n",
        "    EDGES = 5\n",
        "\n",
        "\"\"\"\n",
        "First method for extracting the features from the input image,\n",
        "by reducing its dimensions and turning it into a vector.\n",
        "\"\"\"\n",
        "def image_to_vector(image, size):\n",
        "    # resize the image to a fixed size, then flatten the image into\n",
        "    # a list of raw pixel intensities\n",
        "    return cv2.resize(image, dsize=size, interpolation=cv2.INTER_CUBIC).flatten()\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Second method for extracting the features from the input image,\n",
        "by finding the histogram of each image.\n",
        "\"\"\"\n",
        "def image_to_histogram_vector(image):\n",
        "    histogram, bin_edges = np.histogram(image, bins=np.arange(257))\n",
        "    histogram = np.reshape(histogram, (1, 256))\n",
        "    return histogram\n",
        "\n",
        "\"\"\"\n",
        "Third method:\n",
        "Calculates seven Hu invariants of the image.\n",
        "\"\"\"\n",
        "def fd_hu_moments(image):\n",
        "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
        "    return feature\n",
        "\n",
        "\"\"\"\n",
        "Fourth method:\n",
        "PCA (Principal Component Analysis) for or dimensionality reduction\n",
        "\"\"\"\n",
        "def pca_reduction(images):\n",
        "    # Make an instance of the Model\n",
        "    pca = PCA(n_components=.95)\n",
        "    pca.fit(images)\n",
        "    succinct_x = pca.transform(images)\n",
        "    return succinct_x\n",
        "\n",
        "\"\"\"\n",
        "Fifth method:\n",
        "Using Canny-edge detector for contours in the image\n",
        "\"\"\"\n",
        "def cany_edge(image, size):\n",
        "    image = cv2.resize(image, dsize=size, interpolation=cv2.INTER_CUBIC)\n",
        "    edges = cv2.Canny(image, 100, 200)\n",
        "    edges = edges.flatten()\n",
        "    return edges\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Main method to extract features\n",
        "Parameters:\n",
        "    images : images at original size as numpy arrays.\n",
        "    method: Method(Enum), method to use while extract features.\n",
        "            'SIMPLE' =  image_to_vector\n",
        "            'HISTOGRAM' = image_to_histogram_vector \n",
        "            'HUMOMENTS' = fd_hu_moments\n",
        "            'PCA' = pca_reduction\n",
        "            'EDGES' = cany_edge\n",
        "Returns:\n",
        "    succinct_x: images in succinct format\n",
        "\"\"\"\n",
        "def extract_features(images, method=Method.SIMPLE, size= (32, 32)):\n",
        "    # Draw.draw(images, labels)\n",
        "\n",
        "    succinct_x = []\n",
        "    if method == Method.SIMPLE:\n",
        "        # Resize the image to lower the features dimension\n",
        "        flatten_size = size[0] * size[1]\n",
        "        succinct_x = np.empty(shape=(0, flatten_size))\n",
        "        for image in images:\n",
        "            succinct_x = np.vstack([image_to_vector(image, size), succinct_x])\n",
        "\n",
        "    elif method == Method.HISTOGRAM:\n",
        "        succinct_x = np.empty(shape=(0, 256))\n",
        "        for image in images:\n",
        "            succinct_x = np.vstack([image_to_histogram_vector(image), succinct_x])\n",
        "\n",
        "    elif method == Method.HUMOMENTS:\n",
        "        succinct_x = np.empty(shape=(0,7))\n",
        "        for image in images:\n",
        "            succinct_x = np.vstack([fd_hu_moments(image), succinct_x])\n",
        "\n",
        "    elif method == Method.PCA:\n",
        "        # first: create a matrix of all images flatten to a vector\n",
        "        resized = [image_to_vector(image,size) for image in images] # return a list of np.array\n",
        "        resized_images = np.stack(resized, axis=0)\n",
        "        succinct_x = pca_reduction(resized_images)\n",
        "\n",
        "    elif method == Method.EDGES:\n",
        "        flatten_size = size[0] * size[1]\n",
        "        succinct_x = np.empty(shape=(0, flatten_size))\n",
        "        for image in images:\n",
        "            succinct_x = np.vstack([cany_edge(image, size), succinct_x])\n",
        "\n",
        "    return succinct_x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmG520Zq-npa",
        "outputId": "be0fc987-77cc-4d33-ad55-06f80abe77b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extract features method: Method.HUMOMENTS , image size: 20\n",
            "Begins testing the models...\n",
            "Extract features method: Method.HUMOMENTS , image size: 30\n",
            "Begins testing the models...\n",
            "Extract features method: Method.HUMOMENTS , image size: 40\n",
            "Begins testing the models...\n",
            "Extract features method: Method.HUMOMENTS , image size: 50\n",
            "Begins testing the models...\n",
            "Extract features method: Method.HUMOMENTS , image size: 60\n",
            "Begins testing the models...\n",
            "Extract features method: Method.HUMOMENTS , image size: 70\n",
            "Begins testing the models...\n",
            "Extract features method: Method.HUMOMENTS , image size: 80\n",
            "Begins testing the models...\n",
            "Extract features method: Method.HUMOMENTS , image size: 90\n",
            "Begins testing the models...\n",
            "Extract features method: Method.HUMOMENTS , image size: 100\n",
            "Begins testing the models...\n",
            "Extract features method: Method.HUMOMENTS , image size: 110\n",
            "Begins testing the models...\n",
            "Extract features method: Method.HUMOMENTS , image size: 120\n",
            "Begins testing the models...\n",
            "Extract features method: Method.HUMOMENTS , image size: 130\n",
            "Begins testing the models...\n",
            "Extract features method: Method.HUMOMENTS , image size: 140\n",
            "Begins testing the models...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 138, 138, 32)      320       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 138, 138, 32)      0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 69, 69, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 67, 67, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 67, 67, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 33, 33, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 31, 31, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 14400)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                921664    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 949,793\n",
            "Trainable params: 949,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:174: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 6s 270ms/step - loss: 0.7584 - accuracy: 0.4625 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 4s 253ms/step - loss: 0.6948 - accuracy: 0.5250 - val_loss: 0.6548 - val_accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 4s 252ms/step - loss: 0.6952 - accuracy: 0.5375 - val_loss: 0.6749 - val_accuracy: 0.6000\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 4s 253ms/step - loss: 0.6806 - accuracy: 0.5813 - val_loss: 0.6486 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 4s 251ms/step - loss: 0.6220 - accuracy: 0.6938 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 4s 253ms/step - loss: 0.6308 - accuracy: 0.6562 - val_loss: 0.5446 - val_accuracy: 0.7500\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 5s 283ms/step - loss: 0.5637 - accuracy: 0.7063 - val_loss: 0.5797 - val_accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 4s 276ms/step - loss: 0.5417 - accuracy: 0.7312 - val_loss: 0.5892 - val_accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 4s 253ms/step - loss: 0.5263 - accuracy: 0.7500 - val_loss: 0.5442 - val_accuracy: 0.7500\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 4s 251ms/step - loss: 0.5091 - accuracy: 0.7437 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 0.6053 - accuracy: 0.7625 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 4s 251ms/step - loss: 0.4955 - accuracy: 0.7937 - val_loss: 0.6523 - val_accuracy: 0.5500\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 4s 261ms/step - loss: 0.4824 - accuracy: 0.7875 - val_loss: 0.5220 - val_accuracy: 0.8000\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 4s 259ms/step - loss: 0.4973 - accuracy: 0.7437 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 4s 258ms/step - loss: 0.4699 - accuracy: 0.7688 - val_loss: 0.9610 - val_accuracy: 0.7000\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 4s 260ms/step - loss: 0.4224 - accuracy: 0.7750 - val_loss: 0.5165 - val_accuracy: 0.8000\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 4s 254ms/step - loss: 0.4664 - accuracy: 0.8188 - val_loss: 0.4225 - val_accuracy: 0.8000\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 4s 254ms/step - loss: 0.5304 - accuracy: 0.7875 - val_loss: 0.4724 - val_accuracy: 0.8000\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 0.4286 - accuracy: 0.7875 - val_loss: 0.4392 - val_accuracy: 0.8000\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 5s 291ms/step - loss: 0.4616 - accuracy: 0.7937 - val_loss: 0.4327 - val_accuracy: 0.8000\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 4s 250ms/step - loss: 0.4065 - accuracy: 0.8188 - val_loss: 0.5190 - val_accuracy: 0.8000\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 0.5063 - accuracy: 0.7812 - val_loss: 0.4145 - val_accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 4s 251ms/step - loss: 0.4156 - accuracy: 0.8062 - val_loss: 0.4062 - val_accuracy: 0.8000\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.4570 - accuracy: 0.7875 - val_loss: 0.4958 - val_accuracy: 0.8000\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.3315 - accuracy: 0.8562 - val_loss: 0.4628 - val_accuracy: 0.8000\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 4s 247ms/step - loss: 0.4095 - accuracy: 0.8313 - val_loss: 0.4200 - val_accuracy: 0.8000\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.3791 - accuracy: 0.8687 - val_loss: 0.4418 - val_accuracy: 0.8000\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 4s 253ms/step - loss: 0.3576 - accuracy: 0.8313 - val_loss: 0.3352 - val_accuracy: 0.8000\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 4s 247ms/step - loss: 0.4537 - accuracy: 0.8188 - val_loss: 0.2898 - val_accuracy: 0.8000\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 0.3346 - accuracy: 0.8687 - val_loss: 0.3621 - val_accuracy: 0.8500\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.3275 - accuracy: 0.8625 - val_loss: 0.3064 - val_accuracy: 0.8500\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 0.3188 - accuracy: 0.8813 - val_loss: 0.4673 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 4s 252ms/step - loss: 0.3065 - accuracy: 0.8875 - val_loss: 0.5222 - val_accuracy: 0.8500\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 4s 262ms/step - loss: 0.3491 - accuracy: 0.8875 - val_loss: 0.7648 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 4s 256ms/step - loss: 0.2969 - accuracy: 0.9000 - val_loss: 0.4213 - val_accuracy: 0.8000\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 4s 256ms/step - loss: 0.3509 - accuracy: 0.8750 - val_loss: 0.3485 - val_accuracy: 0.8500\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 4s 253ms/step - loss: 0.3127 - accuracy: 0.8938 - val_loss: 0.5323 - val_accuracy: 0.8500\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 4s 258ms/step - loss: 0.3038 - accuracy: 0.8687 - val_loss: 0.2434 - val_accuracy: 0.8500\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 4s 260ms/step - loss: 0.3527 - accuracy: 0.8875 - val_loss: 0.3395 - val_accuracy: 0.9000\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 4s 255ms/step - loss: 0.2232 - accuracy: 0.9187 - val_loss: 0.4344 - val_accuracy: 0.8000\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 4s 260ms/step - loss: 0.2429 - accuracy: 0.8875 - val_loss: 0.3579 - val_accuracy: 0.8500\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 4s 255ms/step - loss: 0.2410 - accuracy: 0.9187 - val_loss: 0.5841 - val_accuracy: 0.9000\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 5s 300ms/step - loss: 0.2501 - accuracy: 0.8813 - val_loss: 0.3489 - val_accuracy: 0.8500\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 4s 252ms/step - loss: 0.2977 - accuracy: 0.8875 - val_loss: 0.2982 - val_accuracy: 0.8500\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 4s 252ms/step - loss: 0.2521 - accuracy: 0.9062 - val_loss: 0.3423 - val_accuracy: 0.9000\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 4s 254ms/step - loss: 0.2144 - accuracy: 0.9187 - val_loss: 0.2002 - val_accuracy: 0.8500\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 4s 253ms/step - loss: 0.2940 - accuracy: 0.8813 - val_loss: 0.2573 - val_accuracy: 0.8500\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 0.3059 - accuracy: 0.8813 - val_loss: 0.3219 - val_accuracy: 0.8500\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 4s 250ms/step - loss: 0.1866 - accuracy: 0.9438 - val_loss: 0.3109 - val_accuracy: 0.9000\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 0.2775 - accuracy: 0.9125 - val_loss: 0.3488 - val_accuracy: 0.8500\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.1759 - accuracy: 0.9250 - val_loss: 0.3065 - val_accuracy: 0.8500\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.2293 - accuracy: 0.9312 - val_loss: 0.7455 - val_accuracy: 0.8500\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 4s 260ms/step - loss: 0.2269 - accuracy: 0.9187 - val_loss: 0.4723 - val_accuracy: 0.8500\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 4s 260ms/step - loss: 0.2352 - accuracy: 0.9125 - val_loss: 0.5817 - val_accuracy: 0.8500\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 4s 253ms/step - loss: 0.2846 - accuracy: 0.9187 - val_loss: 0.4096 - val_accuracy: 0.8500\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 4s 251ms/step - loss: 0.2873 - accuracy: 0.9187 - val_loss: 0.2684 - val_accuracy: 0.8500\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 4s 251ms/step - loss: 0.2343 - accuracy: 0.9125 - val_loss: 0.2503 - val_accuracy: 0.8500\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.2594 - accuracy: 0.9187 - val_loss: 0.2796 - val_accuracy: 0.8500\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 4s 251ms/step - loss: 0.2355 - accuracy: 0.9062 - val_loss: 0.3111 - val_accuracy: 0.8500\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 4s 246ms/step - loss: 0.2507 - accuracy: 0.9250 - val_loss: 0.4577 - val_accuracy: 0.8500\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.2518 - accuracy: 0.9062 - val_loss: 0.1887 - val_accuracy: 0.9500\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 0.2757 - accuracy: 0.9062 - val_loss: 0.1931 - val_accuracy: 0.8500\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 4s 247ms/step - loss: 0.1950 - accuracy: 0.9250 - val_loss: 0.3692 - val_accuracy: 0.8500\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 0.2393 - accuracy: 0.8938 - val_loss: 0.2719 - val_accuracy: 0.9000\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 4s 250ms/step - loss: 0.1539 - accuracy: 0.9563 - val_loss: 0.1934 - val_accuracy: 0.9000\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 4s 251ms/step - loss: 0.1727 - accuracy: 0.9187 - val_loss: 0.5522 - val_accuracy: 0.9000\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 4s 250ms/step - loss: 0.1830 - accuracy: 0.9250 - val_loss: 0.2959 - val_accuracy: 0.8500\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 4s 251ms/step - loss: 0.1624 - accuracy: 0.9312 - val_loss: 0.5565 - val_accuracy: 0.8500\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.1766 - accuracy: 0.9438 - val_loss: 0.2076 - val_accuracy: 0.8500\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 4s 250ms/step - loss: 0.1899 - accuracy: 0.9187 - val_loss: 0.2781 - val_accuracy: 0.9000\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 4s 247ms/step - loss: 0.1724 - accuracy: 0.9312 - val_loss: 0.3187 - val_accuracy: 0.8500\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.1757 - accuracy: 0.9375 - val_loss: 0.6418 - val_accuracy: 0.8500\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 4s 247ms/step - loss: 0.1667 - accuracy: 0.9125 - val_loss: 0.1286 - val_accuracy: 0.9500\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 4s 250ms/step - loss: 0.1976 - accuracy: 0.9187 - val_loss: 0.3477 - val_accuracy: 0.8500\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 4s 251ms/step - loss: 0.1849 - accuracy: 0.9375 - val_loss: 0.7924 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 4s 246ms/step - loss: 0.2333 - accuracy: 0.9438 - val_loss: 0.2327 - val_accuracy: 0.8500\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.1572 - accuracy: 0.9500 - val_loss: 0.3425 - val_accuracy: 0.9000\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 4s 245ms/step - loss: 0.2645 - accuracy: 0.9187 - val_loss: 0.3142 - val_accuracy: 0.9000\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 4s 251ms/step - loss: 0.1701 - accuracy: 0.9312 - val_loss: 0.2757 - val_accuracy: 0.9000\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.1612 - accuracy: 0.9563 - val_loss: 0.1668 - val_accuracy: 0.9000\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.1400 - accuracy: 0.9563 - val_loss: 0.3453 - val_accuracy: 0.8500\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 0.1816 - accuracy: 0.9250 - val_loss: 0.3116 - val_accuracy: 0.9000\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 4s 250ms/step - loss: 0.1843 - accuracy: 0.9062 - val_loss: 0.1545 - val_accuracy: 0.9500\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 4s 251ms/step - loss: 0.1790 - accuracy: 0.9375 - val_loss: 0.1900 - val_accuracy: 0.9500\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 4s 247ms/step - loss: 0.1840 - accuracy: 0.9187 - val_loss: 0.2683 - val_accuracy: 0.9000\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 4s 249ms/step - loss: 0.2939 - accuracy: 0.9312 - val_loss: 0.1668 - val_accuracy: 0.9000\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 4s 247ms/step - loss: 0.1397 - accuracy: 0.9688 - val_loss: 0.2824 - val_accuracy: 0.9000\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.1486 - accuracy: 0.9500 - val_loss: 0.2624 - val_accuracy: 0.8500\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.1309 - accuracy: 0.9688 - val_loss: 0.2280 - val_accuracy: 0.9000\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 4s 250ms/step - loss: 0.1679 - accuracy: 0.9375 - val_loss: 0.2749 - val_accuracy: 0.8500\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 4s 248ms/step - loss: 0.1773 - accuracy: 0.9375 - val_loss: 0.1266 - val_accuracy: 0.9500\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 4s 254ms/step - loss: 0.1301 - accuracy: 0.9500 - val_loss: 0.2987 - val_accuracy: 0.8500\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 4s 259ms/step - loss: 0.1762 - accuracy: 0.9312 - val_loss: 0.1855 - val_accuracy: 0.9500\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 4s 263ms/step - loss: 0.1639 - accuracy: 0.9438 - val_loss: 0.1320 - val_accuracy: 0.9000\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 4s 262ms/step - loss: 0.1682 - accuracy: 0.9250 - val_loss: 0.1806 - val_accuracy: 0.9500\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 4s 261ms/step - loss: 0.1662 - accuracy: 0.9500 - val_loss: 0.1173 - val_accuracy: 0.9500\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 4s 265ms/step - loss: 0.1663 - accuracy: 0.9187 - val_loss: 0.1921 - val_accuracy: 0.9500\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 4s 259ms/step - loss: 0.0890 - accuracy: 0.9625 - val_loss: 0.4182 - val_accuracy: 0.8500\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 4s 258ms/step - loss: 0.2284 - accuracy: 0.9062 - val_loss: 0.2201 - val_accuracy: 0.9500\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 4s 255ms/step - loss: 0.0655 - accuracy: 0.9688 - val_loss: 0.2267 - val_accuracy: 0.9000\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Final accuracy: 100.0%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Activation, Conv2D, Flatten, Dense, Dropout, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from numpy.random import seed\n",
        "\n",
        "\"\"\"\n",
        "Shuffle the data and split it into train & test sets.\n",
        "Parameters:\n",
        "    X: numpy matrix, representing the images as vectors - each row is the image features.\n",
        "    Y: numpy vector of the labels.\n",
        "Returns:\n",
        "    trainX\n",
        "    trainY\n",
        "    testX\n",
        "    testY \n",
        "    imagesTest - images of test set at original size - for the Draw method.\n",
        "\"\"\"\n",
        "def splitTestTrain(X, Y):\n",
        "    trainSize = (int)(0.8 * X.shape[0])\n",
        "    Y = np.reshape(Y, (Y.shape[0], 1))\n",
        "    indexes = np.arange(200)\n",
        "    indexes = np.reshape(indexes, (200, 1))\n",
        "    # to concatenate the data features with the labels\n",
        "    # labels now is data[:, -1]\n",
        "    data = np.concatenate((X, Y, indexes), axis=1)\n",
        "    np.random.shuffle(data)\n",
        "    trainX = data[: trainSize, :-2]\n",
        "    trainY = data[: trainSize, -2]\n",
        "    testX = data[trainSize:, :-2]\n",
        "    testY = data[trainSize:, -2]\n",
        "    imagesTest = data[trainSize:, -1]\n",
        "    return trainX, trainY, testX, testY, imagesTest\n",
        "\n",
        "\"\"\"\n",
        "Training Model: \n",
        "\"\"\"\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # 1) Load images and labels\n",
        "    pathX = \"../content/gdrive/My Drive/the real deal/head_ct/*.png\"\n",
        "    pathY = '../content/gdrive/My Drive/the real deal/labels.csv'\n",
        "\n",
        "    files = sorted(glob.glob(pathX))\n",
        "    labels_df = pd.read_csv(pathY)\n",
        "    labels = np.array(labels_df[' hemorrhage'].tolist())\n",
        "    images = np.array([cv2.imread(path, cv2.IMREAD_GRAYSCALE) for path in files])\n",
        "\n",
        "    # Run on variety of image size options:\n",
        "    for s in range(20, 150, 10):\n",
        "        # 2) Extract the features with one of four methods: 'SIMPLE', 'HISTOGRAM', 'HUMOMENTS' and 'PAC'.\n",
        "        # see 'Extract' doc.\n",
        "        method_to_extract_features = Method.HUMOMENTS\n",
        "        X = extract_features(images, method=method_to_extract_features, size=(s, s))\n",
        "        print('Extract features method:', method_to_extract_features, \", image size:\", s)\n",
        "\n",
        "        # 3) Split data into train & test sets, including shuffle of the data\n",
        "        trainX, trainY, testX, testY, testIm = splitTestTrain(X, labels)\n",
        "\n",
        "        # 4) Train the models\n",
        "        print('Begins testing the models...')\n",
        "\n",
        "        results = np.zeros(9)\n",
        "        nb_iteration = 10\n",
        "     \n",
        "    # load the images and the labels:\n",
        "    images, Y = load_samples_as_images(pathX, pathY, s, s)\n",
        "\n",
        "    # split the dataset into train (80%), validation (10%) and test (10%) sets.\n",
        "    train_images, test_images, train_labels, test_labels = train_test_split(images, Y, test_size=0.2,\n",
        "                                                                            random_state=1)\n",
        "    val_images, test_images, val_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.5,\n",
        "                                                                        random_state=1)\n",
        "\n",
        "    # ----- Build the model: -----\n",
        "\n",
        "    # The first layer in the model is convolution layer-\n",
        "    # hence we need to provide the keyword argument \"input_shape\"\n",
        "    # \"input_shape\" = (image width, image height, number of channels)\n",
        "    input_shape = (s, s, 1)\n",
        "\n",
        "    # Sequential = pre-built keras model where you can just add the layers\n",
        "    model = Sequential()\n",
        "\n",
        "    # ----- First convolution layer: -----\n",
        "    #   number of filters (the dimensionality of the output space) = 32\n",
        "    #   kernel size (specifying the height and width of the 2D convolution window) = (3,3)\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "\n",
        "    # activation layer: (Relu)\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # max-pooling layer:\n",
        "    #   shrink the size of the first conv layer's output in 75% to be:\n",
        "    #   from dimension of: (s - kernel_size + 1) , (s - kernel_size + 1)\n",
        "    #   to dimension:   (s - kernel_size + 1)/2 , (s - kernel_size + 1)/2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # ----- Second convolution layer: -----\n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # ----- Third convolution layer: -----\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Finally, adding dense layers as they are used to predict the labels.\n",
        "\n",
        "    # flatten layer: expands a three-dimensional vector into a one-dimensional vector\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # ----- Fourth layer: dense-----\n",
        "    model.add(Dense(64))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # Dropout is an overfitting reduction technique.\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # ----- Fifth and last output  layer: -----\n",
        "    # The Dense function has the argument \"1\" because the net output is the hematoma x non-hematoma classification\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # The output is either 0 or 1 and this can be obtained with a sigmoid function.\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    # print the model summary:\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "    # compile the network:\n",
        "    #   loss function binary cross entropy > to predict 0 or 1\n",
        "    #\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                              optimizer='rmsprop',\n",
        "                              metrics=['accuracy'])\n",
        "\n",
        "    nb_train_samples = len(train_images)\n",
        "    nb_validation_samples = len(val_images)\n",
        "    epochs = 100\n",
        "    batch_size = 10\n",
        "\n",
        "    # this is the augmentation configuration we will use for training\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        shear_range=0.0,\n",
        "        zoom_range=0.1,\n",
        "        rotation_range=10,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "    # this is the augmentation configuration we will use for validation:\n",
        "    val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow(\n",
        "        train_images[..., np.newaxis],\n",
        "        train_labels,\n",
        "        batch_size=batch_size)\n",
        "\n",
        "    validation_generator = val_datagen.flow(\n",
        "        val_images[..., np.newaxis],\n",
        "        val_labels,\n",
        "        batch_size=batch_size)\n",
        "\n",
        "\n",
        "    history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=nb_train_samples // batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=nb_validation_samples // batch_size)\n",
        "    \n",
        "    model.save(\"Hemorrhage.h5\")\n",
        "\n",
        "    print(\"Final accuracy: \" + str(model.evaluate(test_images[..., np.newaxis] / 255., test_labels)[1] * 100) + \"%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "N-eUJIiMdZbQ",
        "outputId": "5c6ed3d5-7e73-4264-a1e3-f8bd3618bd65"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Plotting Training VS Validation Accuracy\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "kudxjQF3KGUL",
        "outputId": "77b84816-0a8a-479f-fddb-af1511ade434"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-65b31284-bd4d-4d92-91e0-0e2546b22610\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-65b31284-bd4d-4d92-91e0-0e2546b22610\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hemorrhage.jpg to hemorrhage.jpg\n",
            "hemorrhage.jpg\n",
            "[[1.]]\n"
          ]
        }
      ],
      "source": [
        "#Upload test image and use model to predict likelihood of a Hemorrhage\n",
        "#Outputs the chance that the CT scan detected a brain hemorrhage\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(140, 140))\n",
        "  x = image.img_to_array(img)\n",
        "  x = tf.image.rgb_to_grayscale(x)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = x/255.0\n",
        "\n",
        "  classes = model.predict(x, batch_size=10)\n",
        "  print(fn)\n",
        "  print(classes)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Hemorrhage Detection",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}